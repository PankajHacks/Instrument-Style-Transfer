{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digvijay/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import librosa\n",
    "import os\n",
    "from IPython.display import Audio, display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Enter the audio folder name where you have stored 5 second audio files of one instrument for training\n",
    "AUDIO_FOLDER = 'spectro_piano'\n",
    "files = [f for f in os.listdir(AUDIO_FOLDER+'/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_FFT = 2048\n",
    "#the instructions in this function has been taken from DmitryUlyanov/neural-style-audio-torch\n",
    "#link is https://github.com/DmitryUlyanov/neural-style-audio-torch/blob/master/get_spectrogram.py\n",
    "def read_audio_spectum(file):\n",
    "    x, fs = librosa.load(file)\n",
    "    S = librosa.stft(x, N_FFT)\n",
    "    mag, phase = librosa.magphase(S)\n",
    "    S = np.log1p(np.abs(mag[:1024,:256]))\n",
    "    S_new = np.zeros((1024,256))\n",
    "    S_new[:S.shape[0], :S.shape[1]] = S\n",
    "    S = S_new\n",
    "    return S, fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_list = []\n",
    "for file in files:\n",
    "    a_audio, fs = read_audio_spectum(AUDIO_FOLDER+'/'+file)\n",
    "    a_audio = np.reshape(a_audio,newshape=(-1,256,1))\n",
    "    audio_list.append(a_audio)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_npy = np.asarray(audio_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(AUDIO_FOLDER,audio_npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
