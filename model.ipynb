{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "learning_rate = 0.0001\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_convlayer(X, w_name, b_name, w_shape ):\n",
    "    w = tf.get_variable(w_name, w_shape, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    b = tf.get_variable(b_name, w_shape[3], initializer = tf.constant_initializer(0))\n",
    "    layer = tf.nn.conv2d(input = X , filter = w, strides = [1,2,2,1] , padding = 'SAME') + b\n",
    "    layer = tf.nn.leaky_relu(layer)\n",
    "#     layer = tf.layers.batch_normalization(layer)\n",
    "    return layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_deconvlayer(X, w_name, b_name, w_shape):\n",
    "    w = tf.get_variable(w_name, w_shape, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    b = tf.get_variable(b_name, w_shape[2], initializer = tf.constant_initializer(0))\n",
    "    shape = tf.shape(X)\n",
    "    out_shape = tf.stack([shape[0],shape[1]*2,shape[2]*2,tf.shape(w)[2]])\n",
    "    layer = tf.nn.conv2d_transpose(value = X , filter = w, strides = [1,2,2,1] ,output_shape=out_shape, padding = 'SAME') + b\n",
    "    layer = tf.nn.leaky_relu(layer)\n",
    "#     layer = tf.layers.batch_normalization(layer)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(image, scope, reuse=False):\n",
    "    with tf.variable_scope(scope):\n",
    "        if(reuse):\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "        \n",
    "        image_h = tf.shape(image)[1]\n",
    "        image_w = tf.shape(image)[2]\n",
    "    \n",
    "        disc1 = make_convlayer(image,'w1','b1', [4,4,1,32])\n",
    "        \n",
    "        disc2 = make_convlayer(disc1,'w2','b2', [4,4,32,64])\n",
    "        \n",
    "        disc3 = make_convlayer(disc2,'w3','b3', [4,4,64,128])\n",
    "        \n",
    "        #fully connected layers\n",
    "       \n",
    "        disc_f1 =tf.reshape(disc3, shape=[-1, 128 * 32* 128])\n",
    "        disc_wf1 = tf.get_variable('wf1', [128 * 32* 128,1024], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        disc_bf1 = tf.get_variable('bf1', [1024], initializer = tf.constant_initializer(0))\n",
    "        disc_f1 = tf.matmul(disc_f1,disc_wf1) + disc_bf1\n",
    "        disc_f1 = tf.nn.leaky_relu(disc_f1)\n",
    "#         disc_f1 = tf.layers.batch_normalization(disc_f1)\n",
    "        \n",
    "        #output sigmoid layer\n",
    "        disc_wf2 = tf.get_variable('wf2', [1024,1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        disc_bf2 = tf.get_variable('bf2', [1], initializer = tf.constant_initializer(0))\n",
    "        disc_f2 = tf.matmul(disc_f1,disc_wf2) + disc_bf2\n",
    "        \n",
    "        return disc_f2\n",
    "     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(image, scope, reuse=False):\n",
    "    with tf.variable_scope(scope):\n",
    "        if(reuse):\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "        #encoder layers\n",
    "        enc_layer1 = make_convlayer(image,'enc_w1','enc_b1', [4,4,1,32])\n",
    "       \n",
    "        enc_layer2 = make_convlayer(enc_layer1,'enc_w2','enc_b2', [4,4,32,64])\n",
    "        \n",
    "        enc_layer3 = make_convlayer(enc_layer2,'enc_w3','enc_b3', [4,4,64,128])\n",
    "        \n",
    "        enc_final = make_convlayer(enc_layer3,'enc_w4','enc_b4', [4,4,128,256])\n",
    "        \n",
    "        \n",
    "        #decoder layers \n",
    "        dec_layer4 = make_deconvlayer(enc_final,'dec_w4','dec_b4', [4,4,128,256])\n",
    "        \n",
    "        dec_layer3 = make_deconvlayer(dec_layer4,'dec_w3','dec_b3', [4,4,64,128])\n",
    "        \n",
    "        dec_layer2 = make_deconvlayer(dec_layer3,'dec_w2','dec_b2',[4,4,32,64])\n",
    "        \n",
    "        generated_image = make_deconvlayer(dec_layer2,'dec_w1','dec_b1',[4,4,1,32])\n",
    "        \n",
    "        return generated_image\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load audio and generate spectrograms\n",
    "def prepare_data():\n",
    "    train_piano =None\n",
    "    train_violin = None\n",
    "    return train_piano, train_violin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train\n",
    "height = 1024\n",
    "width = 256\n",
    "channels =1\n",
    "\n",
    "train_piano = tf.placeholder(tf.float32,[None, height,width, channels], name= 'piano_data')\n",
    "train_violin = tf.placeholder(tf.float32,[None, height,width, channels], name= 'violin_data')\n",
    "\n",
    "# train_piano= tf.random_uniform([1,256,256,1])\n",
    "# train_violin= tf.random_uniform([1,256,256,1])\n",
    "\n",
    "#phase variable for batch norm\n",
    "phase = tf.placeholder(tf.bool, name='phase')\n",
    "\n",
    "#scope_variables\n",
    "GEN_PIANO = 'generator_piano'\n",
    "GEN_VIOLIN = 'generator_violin'\n",
    "DISC_PIANO = 'discriminator_piano'\n",
    "DISC_VIOLIN = 'discriminator_violin'\n",
    "\n",
    "gen_piano = generator(train_violin, GEN_PIANO)\n",
    "gen_violin = generator(train_piano, GEN_VIOLIN)\n",
    "\n",
    "recons_violin =generator(gen_piano, GEN_VIOLIN, reuse = True)\n",
    "recons_piano = generator(gen_violin, GEN_PIANO,reuse = True)\n",
    "\n",
    "disc_piano_gen = discriminator(gen_piano, DISC_PIANO)\n",
    "disc_violin_gen = discriminator(gen_violin, DISC_VIOLIN)\n",
    "\n",
    "disc_piano_real = discriminator(train_piano, DISC_PIANO, reuse = True)\n",
    "disc_violin_real = discriminator(train_violin, DISC_VIOLIN, reuse = True)\n",
    "\n",
    "#reconstruction loss\n",
    "loss_recons_violin = tf.reduce_mean(tf.losses.mean_squared_error(train_violin, recons_violin))\n",
    "loss_recons_piano = tf.reduce_mean(tf.losses.mean_squared_error(train_piano, recons_piano))\n",
    "\n",
    "#generator loss\n",
    "loss_gen_violin = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_violin_gen,\n",
    "                                                                         labels=tf.ones_like(disc_violin_gen)))\n",
    "loss_gen_piano = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_piano_gen,\n",
    "                                                                         labels=tf.ones_like(disc_piano_gen)))\n",
    "\n",
    "#discriminator loss for real samples\n",
    "loss_disc_violin_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_violin_real,\n",
    "                                                                         labels=tf.ones_like(disc_violin_real)))\n",
    "loss_disc_piano_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_piano_real,\n",
    "                                                                         labels=tf.ones_like(disc_piano_real)))\n",
    "\n",
    "#discriminator loss for generated samples\n",
    "loss_disc_violin_gen = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_violin_gen,\n",
    "                                                                         labels=tf.zeros_like(disc_violin_gen)))\n",
    "loss_disc_piano_gen = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_piano_gen,\n",
    "                                                                         labels=tf.zeros_like(disc_piano_gen)))\n",
    "\n",
    "#combined discriminator loss\n",
    "loss_disc_violin = loss_disc_violin_real + loss_disc_violin_gen\n",
    "loss_disc_piano = loss_disc_piano_real + loss_disc_piano_gen\n",
    "\n",
    "loss_disc = loss_disc_violin + loss_disc_piano\n",
    "\n",
    "#combined generator loss\n",
    "loss_gen_violin = loss_gen_violin + loss_recons_violin\n",
    "loss_gen_piano = loss_gen_piano + loss_recons_piano\n",
    "\n",
    "# gen loss\n",
    "loss_gen = loss_gen_violin + loss_gen_piano\n",
    "\n",
    "vars_dis = tf.trainable_variables(DISC_VIOLIN) + tf.trainable_variables(DISC_PIANO)\n",
    "vars_gen = tf.trainable_variables(GEN_VIOLIN) + tf.trainable_variables(GEN_PIANO)\n",
    "\n",
    "disc_trainer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss_disc, var_list= vars_dis)\n",
    "gen_trainer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss_gen, var_list= vars_gen)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "piano_data_file = 'spectro_piano.npy'\n",
    "violin_data_file ='spectro_violin.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "piano = np.load(piano_train_file)\n",
    "violin = np.load(violin_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(epochs):\n",
    "        _, _, piano_generated, violin_generated, lp,lv = sess.run([disc_trainer, gen_trainer,gen_piano, gen_violin,loss_gen_piano,loss_gen_violin], feed_dict={train_piano: piano,train_violin: violin})\n",
    "        print('epoch ', i, \" \", lp, \" \", lv)\n",
    "        saver.save(sess, './model/model.ckpt')\n",
    "        np.save('./result/piano_epoch_'+str(i),piano_generated)\n",
    "        np.save('./result/violin_epoch_'+str(i),violin_generated)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
